# Ressources intéressantes pour faire du NLP Français

[Google](http://google.com/) 

**liste de ressources**
[question](http://french.stackexchange.com/questions/13542/natural-language-processing-sentiment-classification-api-for-french-text) sur stackoverflow qui aborde le problème et dont beaucoup de réponses mentionnent des ressources intéressantes

**données labelisées analyse de sentiment**
DEFT est une compétition annuelle de classification de données. 

en 2015 il fallait classer des tweets par sentiment (PEUR, VALORISATION, POSITIF, NEGATIF, etc) - propose donc un [corpus](https://deft.limsi.fr/2015/index.php) de tweets labélisés 

**software Stanford NLP**
Stanford propose des [solutions](https://nlp.stanford.edu/software/) en Java pour résoudre certains process spécifiques de NLP comme :
* maximum entropy part of speech tagger

**dictionnaire de mots français avec lemmatiseur, prononciation etc**
gros [dictionnaire](http://lexique.org/utilisations.php) de mots français sous format excel avec un lemmatiseur mais aussi de nombreuses autres solutions

**dictionnaire de mots classés par polarité et émotion**
[lexicon](http://advanse.lirmm.fr/feel.php) avec 14 000 mots distincts classés selon les 2 polarités et 6 émotions de Ekman, 1992 (joie / peur / tristesse / colère / surprise / dégoût)

**librairie python**
[tutoriel](http://blog.fouadhamdi.com/introduction-a-nltk/) sur la partie française de nltk qui est une librairie python permettant de faire du NLP 

**corpus de textes (python)**
[documentation](http://www.nltk.org/book/ch02.html) de nltk (mentionnée au dessus) qui explique comment accéder à des corpus de textes en français sur python

**papier**
[papier](http://lrec-conf.org/proceedings/lrec2010/pdf/385_Paper.pdf) sur l'utilisation de twitter pour créer un corpus labélisé de données
